{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4824c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/Área de Trabalho/research-project/py37/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys, io, os\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/renan/MATLAB/R2021b/runtime/glnxa64/\"\n",
    "\n",
    "import numpy as np\n",
    "from libs import myDehankelization, myHankelization, myBTD\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matlab\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy.io import savemat\n",
    "from scipy.signal import resample\n",
    "import ecg_plot\n",
    "import scipy.fftpack as fftpack\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8775bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnostic  db                  \n",
       "AF          WFDB_CPSC2018           10\n",
       "            WFDB_CPSC2018_2         10\n",
       "            WFDB_ChapmanShaoxing    10\n",
       "            WFDB_Ga                 10\n",
       "            WFDB_PTBXL              10\n",
       "SR          WFDB_CPSC2018           10\n",
       "            WFDB_CPSC2018_2         10\n",
       "            WFDB_ChapmanShaoxing    10\n",
       "            WFDB_Ga                 10\n",
       "            WFDB_Ningbo             10\n",
       "            WFDB_PTBXL              10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f'../workdata/mu/mu.pkl')\n",
    "df.groupby(['diagnostic', 'db']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f54079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       fval             relfval          relstep          delta        rho\n",
      "       =1/2*norm(F)^2   TolFun = 1e-05   TolX = 1e-05\n",
      "\n",
      "   0:  3.40400905e+09 |\n",
      "   1:  3.25897730e+09 | 4.26061568e-02 | 3.00000000e-01 | 5.9529e+01 | 7.0482e+00\n",
      "   2:  2.22598982e+09 | 3.03462025e-01 | 1.43452693e-01 | 2.9764e+01 | 1.8552e+00\n",
      "   3:  1.44093372e+09 | 2.30626915e-01 | 6.99428218e-02 | 1.4937e+01 | 1.2063e+00\n",
      "   4:  1.00142013e+09 | 1.29116457e-01 | 1.36366165e-01 | 2.9874e+01 | 9.8303e-01\n",
      "   5:  7.61094857e+08 | 7.06006562e-02 | 2.61397131e-01 | 5.9749e+01 | 1.0047e+00\n",
      "   6:  4.36532594e+08 | 9.53470623e-02 | 5.05907888e-01 | 1.1950e+02 | 1.1338e+00\n",
      "   7:  1.52535685e+08 | 8.34301277e-02 | 8.55561389e-01 | 2.3899e+02 | 1.2079e+00\n",
      "   8:  1.24880197e+08 | 8.12438750e-03 | 2.97821835e-01 | 5.8324e+01 | 4.9404e-01\n",
      "   9:  4.89109031e+07 | 2.23175945e-02 | 2.57121322e-01 | 1.1665e+02 | 9.6924e-01\n",
      "  10:  2.91528650e+07 | 5.80434358e-03 | 1.18382570e-01 | 5.8324e+01 | 9.7480e-01\n",
      "  11:  1.49526546e+07 | 4.17161361e-03 | 2.29792851e-01 | 1.1665e+02 | 8.4975e-01\n",
      "  12:  8.03444771e+06 | 2.03237029e-03 | 2.17793074e-01 | 1.2001e+02 | 7.0610e-01\n",
      "  13:  6.16452669e+06 | 5.49329040e-04 | 4.19302418e-01 | 2.4002e+02 | 7.3849e-01\n",
      "  14:  6.10107958e+06 | 1.86389377e-05 | 9.63605136e-02 | 6.8214e+01 | 3.2778e-02\n",
      "\n",
      "       fval             relfval          relstep          delta        rho\n",
      "       =1/2*norm(F)^2   TolFun = 1e-05   TolX = 1e-05\n",
      "\n",
      "  15:  4.93453010e+06 | 3.42698701e-04 | 1.91013814e-01 | 1.3643e+02 | 1.0513e+00\n",
      "  16:  3.81495657e+06 | 3.28898518e-04 | 1.08801251e-01 | 6.8619e+01 | 5.4426e-01\n",
      "  17:  2.45304274e+06 | 4.00091130e-04 | 2.10489643e-01 | 1.3724e+02 | 9.4576e-01\n",
      "  18:  2.22768092e+06 | 6.62048252e-05 | 1.53903404e-01 | 1.3724e+02 | 1.0036e+00\n",
      "  19:  2.11078347e+06 | 3.43411104e-05 | 1.53474175e-01 | 1.3724e+02 | 7.7573e-01\n",
      "  20:  1.87228407e+06 | 7.00642673e-05 | 2.47001689e-01 | 1.3724e+02 | 9.8781e-01\n",
      "\n",
      "Maximum number of iterations reached.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANK = 5\n",
    "LR = 40\n",
    "MAX_ITER = 20\n",
    "TOLERANCE_FUN = 1.0E-5\n",
    "TOLERANCE_X = 1.0E-5\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for index, row in df.iloc[0:1].iterrows():\n",
    "    recording = row['data']\n",
    "    leads, samples = recording.shape\n",
    "    new_freq = 100\n",
    "    time_rec = samples/250\n",
    "    n_samples = int(time_rec*new_freq)\n",
    "    recording = resample(recording, n_samples, axis=1)\n",
    "\n",
    "    T = np.zeros((50, 51, leads))\n",
    "    my_hankelization = myHankelization.initialize()\n",
    "    for i in range(0, leads):\n",
    "        vec = matlab.double(recording[i].tolist(), size=recording[i].shape)\n",
    "        T[:, :, i] = my_hankelization.hankelization(vec)\n",
    "    my_hankelization.terminate()\n",
    "\n",
    "    T = matlab.double(T.tolist(), size=T.shape)\n",
    "    R = matlab.double([rank], size=(1, 1))\n",
    "    max_iter = matlab.double([MAX_ITER], size=(1, 1))\n",
    "    multirank = matlab.double([LR, LR, 1], size=(1, 3))\n",
    "\n",
    "    tol_fun = matlab.double([TOLERANCE_FUN], size=(1, 1))\n",
    "    tol_x = matlab.double([TOLERANCE_X], size=(1, 1))\n",
    "\n",
    "    btd = myBTD.initialize()\n",
    "    result, output = btd.myBTD(R, multirank, max_iter, tol_fun, tol_x, T, nargout=2)\n",
    "    results_df = results_df.append(output, ignore_index=True) \n",
    "    btd.terminate()\n",
    "\n",
    "\n",
    "    path = f'../workdata/mu/rank_{R._data[0]}'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    with open(f'{path}/{row.name}.npy', 'wb') as file:\n",
    "        np.save(file, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab746d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fval': 1872284.0658973404,\n",
       " 'relfval': 7.006426726644349e-05,\n",
       " 'relstep': 0.24700168858990879,\n",
       " 'delta': 137.2374153483836,\n",
       " 'rho': 0.9878119701877677,\n",
       " 'relerr': 0.023452224946064863}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e43c7a",
   "metadata": {},
   "source": [
    "output.fval         - The value of the objective function f in every iteration.\n",
    "\n",
    "output.delta        - The trust region radius at every step attempt.\n",
    "\n",
    "output.relstep      - The step size relative to the norm of the current iterate in every iteration.\n",
    "\n",
    "output.rho          - The trustworthiness at every step attempt.\n",
    "\n",
    "output.relfval      - The difference in objective function value between every two successive iterates, relative to its initial value.\n",
    "\n",
    "output.relerr       - O erro relativo entre o tensor e seu BTD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7aac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources(filename):\n",
    "    with open(f\"tensor_data/6d2698_indexes/{filename}\", 'rb') as f:\n",
    "            output = np.load(f, allow_pickle=True)\n",
    "    output = np.array(output)\n",
    "    sources = np.empty((0, 100), int)\n",
    "    contrib_sources = np.empty((0, 12), int)\n",
    "    my_dehankelization = myDehankelization.initialize()\n",
    "    for i in range(0, len(output)):\n",
    "        a = np.array(output[i][0])\n",
    "        b = np.array(output[i][1]).T\n",
    "        c = np.array(output[i][2]).T\n",
    "        contrib_sources = np.append(contrib_sources, c, axis=0)\n",
    "        mixing_matrix = np.dot(a, b)\n",
    "        m_hankel = matlab.double(mixing_matrix.tolist(), size=mixing_matrix.shape)\n",
    "        source = my_dehankelization.dehankelization(m_hankel)\n",
    "        sources = np.append(sources, np.array(source).T, axis=0)\n",
    "    my_dehankelization.terminate()\n",
    "    return sources, contrib_sources\n",
    "\n",
    "\n",
    "def get_likely_atrial(sources, contrib_sources):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    potentials_aa = np.empty((0, 100), int)\n",
    "    for i, source in enumerate(sources):\n",
    "        fourier = np.fft.fft(source)\n",
    "        fourier = fourier[:int(len(source)/2)]\n",
    "        frequencies = np.fft.fftfreq(len(source), d=x[1]-x[0])[:int(len(source)/2)]\n",
    "        frequencies = frequencies[:int(len(source)/2)]\n",
    "        freq = frequencies[np.argmax(np.abs(fourier))]\n",
    "        contrib_source = contrib_sources[i, :]\n",
    "        contrib_source_V1 = contrib_source[1]\n",
    "        power_contrib = (norm(contrib_source_V1*source)**2)/100\n",
    "        if freq > 3 and freq < 9 and power_contrib > 0.0001:\n",
    "            potentials_aa = np.append(potentials_aa, np.array([source]), axis=0)\n",
    "    return potentials_aa\n",
    "\n",
    "\n",
    "def get_atrial_source(potentials_aa):\n",
    "    kurt_pot_aa = [*map(lambda p_aa: kurtosis(p_aa), potentials_aa)]\n",
    "    atrial_source = potentials_aa[kurt_pot_aa.index(max(kurt_pot_aa))]\n",
    "    return atrial_source\n",
    "    \n",
    "    \n",
    "def get_df_atrial():\n",
    "    files = os.listdir('tensor_data/6d2698_indexes')\n",
    "    rows = list()\n",
    "    for filename in files:\n",
    "        sources, contrib_sources = get_sources(filename)\n",
    "        # potentials_aa = get_likely_atrial(sources, contrib_sources)\n",
    "        #if potentials_aa.size != 0:\n",
    "        #    atrial_source = get_atrial_source(potentials_aa)\n",
    "        label = df.loc[int(filename.split('.')[0])].diagnostic\n",
    "        rows.append({\n",
    "              'id': int(filename.split('.')[0]),\n",
    "              'data': sources,\n",
    "              'label': label\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_atrial = get_df_atrial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_atrial = pd.read_pickle('df_atrial.pkl')\n",
    "label_encoder = LabelEncoder()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
