{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4824c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/√Årea de Trabalho/research-project/py37/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys, io, os\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/renan/MATLAB/R2021b/runtime/glnxa64/\";\n",
    "\n",
    "# btd_rnd e btd_nls\n",
    "sys.path.append(\"../matlab/myBTD/myBTD/for_redistribution_files_only\");\n",
    "import myBTD\n",
    "\n",
    "# ll1_rnd e ll1_nls\n",
    "sys.path.append(\"../matlab/myBTD2/myBTD2/for_redistribution_files_only\");\n",
    "import myBTD2\n",
    "\n",
    "import numpy as np\n",
    "from libs import myDehankelization, myHankelization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matlab\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy.io import savemat\n",
    "from scipy.signal import resample\n",
    "import ecg_plot\n",
    "import scipy.fftpack as fftpack\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.linalg import norm\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10de76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling_recording(recording):\n",
    "    OLD_FREQ = 250\n",
    "    NEW_FREQ = 100\n",
    "    leads, sampling = recording.shape\n",
    "    time_rec = sampling/OLD_FREQ\n",
    "    n_samples = int(time_rec*NEW_FREQ)\n",
    "    recording = resample(recording, n_samples, axis=1)\n",
    "    return recording\n",
    "\n",
    "\n",
    "def hankelization(recording):\n",
    "    T = np.zeros((50, 51, recording.shape[0]))\n",
    "    my_hankelization = myHankelization.initialize()\n",
    "    for i in range(0, recording.shape[0]):\n",
    "        vec = matlab.double(recording[i].tolist(), size=recording[i].shape)\n",
    "        T[:, :, i] = my_hankelization.hankelization(vec)\n",
    "    my_hankelization.terminate()\n",
    "    T = matlab.double(T.tolist(), size=T.shape)\n",
    "    return T\n",
    "\n",
    "\n",
    "def run_btd(params):\n",
    "    btd = myBTD.initialize()\n",
    "    result, output = btd.myBTD(params['rank'], \n",
    "                               params['MULTIRANK'], \n",
    "                               params['MAX_ITER'], \n",
    "                               params['TOLERANCE_FUN'], \n",
    "                               params['TOLERANCE_X'], \n",
    "                               params['DISPLAY'], \n",
    "                               params['recording_hankel'], \n",
    "                               nargout=2)\n",
    "    btd.terminate()\n",
    "    return result, output\n",
    "    \n",
    "    \n",
    "def run_btd2(params):\n",
    "    btd = myBTD2.initialize()\n",
    "    result, output = btd.myBTD2(params['rank'], \n",
    "                                params['LR'], \n",
    "                                params['MAX_ITER'], \n",
    "                                params['TOLERANCE_FUN'], \n",
    "                                params['TOLERANCE_X'], \n",
    "                                params['DISPLAY'], \n",
    "                                params['recording_hankel'], \n",
    "                                nargout=2)\n",
    "    btd.terminate()\n",
    "    return result, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f54079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK: 1\n",
      " - 0/110\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_211434/1565045195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         }\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_btd2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLL1_MODE\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrun_btd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index_aldebaran'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_211434/3847157351.py\u001b[0m in \u001b[0;36mrun_btd\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_btd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyBTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     result, output = btd.myBTD(params.rank, \n\u001b[0m\u001b[1;32m     25\u001b[0m                                \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultirank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "MULTIRANK = matlab.double([40, 40, 1], size=(1, 3))\n",
    "LR = matlab.double([40], size=(1, 1))\n",
    "MAX_ITER = matlab.double([1000], size=(1, 1))\n",
    "TOLERANCE_FUN = matlab.double([1.0E-6], size=(1, 1))\n",
    "TOLERANCE_X = matlab.double([1.0E-6], size=(1, 1))\n",
    "DISPLAY = matlab.logical([False], size=(1, 1))\n",
    "\n",
    "aldebaran_df = pd.read_pickle(f'../workdata/aldebaran/aldebaran.pkl')\n",
    "\n",
    "LL1_MODE = False\n",
    "\n",
    "for rank in range(1, 15):\n",
    "    print(f'RANK: {rank}')\n",
    "    \n",
    "    path = f'../workdata/saga/rank_{rank}'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)  \n",
    "        \n",
    "    rank = matlab.double([rank], size=(1, 1))\n",
    "    \n",
    "    for index, row in aldebaran_df.iterrows():\n",
    "        print(f\" - {index}/{aldebaran_df['filename'].count()}\")\n",
    "        recording = row['data']\n",
    "        recording = resampling_recording(recording)\n",
    "        recording_hankel = hankelization(recording)\n",
    "        \n",
    "        \n",
    "        params = {\n",
    "            'rank': rank,\n",
    "            'lr': LR,\n",
    "            'multirank': MULTIRANK,\n",
    "            'max_iter': MAX_ITER,\n",
    "            'tol_fun': TOLERANCE_FUN,\n",
    "            'tol_x': TOLERANCE_X,\n",
    "            'display': DISPLAY,\n",
    "            'recording_hankel': recording_hankel\n",
    "        }\n",
    "        \n",
    "        result, output = run_btd2(params) if LL1_MODE else run_btd(params)\n",
    "\n",
    "        output['index_aldebaran'] = index\n",
    "        output['rank'] = rank[0][0]\n",
    "        output['lr'] = LR[0][0]\n",
    "        output['filename'] = row['filename']\n",
    "        output['inf'] = row['inf']\n",
    "        output['sup'] = row['sup']                        \n",
    "        output['db'] = row['db']\n",
    "        output['diagnostic'] = row['diagnostic']\n",
    "        output['datetime'] = datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "        with open(f'{path}/{row.name}.npy', 'wb') as file:\n",
    "            np.save(file, output)\n",
    "        \n",
    "        with open('../workdata/saga/results.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(output.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e2fc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../workdata/saga/results.csv'\n",
    "file_exists = os.path.isfile(path)\n",
    "\n",
    "with open(path, 'a') as f:\n",
    "    headers = output.keys()\n",
    "    writer = csv.DictWriter(f, delimiter=',', lineterminator='\\n', fieldnames=headers)\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b46fcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([39.0, 76649502.42348681, 9.542875642777407e-10, 0.00038253172000487785, 0.9821224496607576, 0.9179844756384101, 0.15005582208888485, 0, matlab.double([[1.0]]), matlab.double([[40.0]]), 'Q3000.mat', 1000, 1250, 'WFDB_CPSC2018_2', 'AF', '28/04/2022 23:01:03'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a85683c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "a = results_df.iloc[0].values\n",
    "\n",
    "with open('results17.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86fa1d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58e97573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[76.0 76649486.27235126 9.669357254708835e-13 2.694618340663327e-05\\n 0.9821224496607576 0.918587320015089 0.1500558062794407 1.0 40.0 0.0\\n '28/04/2022 20:13:06' 'Q3000.mat' 1000.0 1250.0 'WFDB_CPSC2018_2' 'AF']\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6544d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/{row.name}.npy', 'r') as file:\n",
    "    d = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['diagnostic'] == 'AF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['diagnostic'] == 'SR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b99cd",
   "metadata": {},
   "source": [
    "output.fval         - The value of the objective function f in every iteration.\n",
    "\n",
    "output.delta        - The trust region radius at every step attempt.\n",
    "\n",
    "output.relstep      - The step size relative to the norm of the current iterate in every iteration.\n",
    "\n",
    "output.rho          - The trustworthiness at every step attempt.\n",
    "\n",
    "output.relfval      - The difference in objective function value between every two successive iterates, relative to its initial value.\n",
    "\n",
    "output.relerr       - O erro relativo entre o tensor e seu BTD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7aac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources(filename):\n",
    "    with open(f\"tensor_data/6d2698_indexes/{filename}\", 'rb') as f:\n",
    "            output = np.load(f, allow_pickle=True)\n",
    "    output = np.array(output)\n",
    "    sources = np.empty((0, 100), int)\n",
    "    contrib_sources = np.empty((0, 12), int)\n",
    "    my_dehankelization = myDehankelization.initialize()\n",
    "    for i in range(0, len(output)):\n",
    "        a = np.array(output[i][0])\n",
    "        b = np.array(output[i][1]).T\n",
    "        c = np.array(output[i][2]).T\n",
    "        contrib_sources = np.append(contrib_sources, c, axis=0)\n",
    "        mixing_matrix = np.dot(a, b)\n",
    "        m_hankel = matlab.double(mixing_matrix.tolist(), size=mixing_matrix.shape)\n",
    "        source = my_dehankelization.dehankelization(m_hankel)\n",
    "        sources = np.append(sources, np.array(source).T, axis=0)\n",
    "    my_dehankelization.terminate()\n",
    "    return sources, contrib_sources\n",
    "\n",
    "\n",
    "def get_likely_atrial(sources, contrib_sources):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    potentials_aa = np.empty((0, 100), int)\n",
    "    for i, source in enumerate(sources):\n",
    "        fourier = np.fft.fft(source)\n",
    "        fourier = fourier[:int(len(source)/2)]\n",
    "        frequencies = np.fft.fftfreq(len(source), d=x[1]-x[0])[:int(len(source)/2)]\n",
    "        frequencies = frequencies[:int(len(source)/2)]\n",
    "        freq = frequencies[np.argmax(np.abs(fourier))]\n",
    "        contrib_source = contrib_sources[i, :]\n",
    "        contrib_source_V1 = contrib_source[1]\n",
    "        power_contrib = (norm(contrib_source_V1*source)**2)/100\n",
    "        if freq > 3 and freq < 9 and power_contrib > 0.0001:\n",
    "            potentials_aa = np.append(potentials_aa, np.array([source]), axis=0)\n",
    "    return potentials_aa\n",
    "\n",
    "\n",
    "def get_atrial_source(potentials_aa):\n",
    "    kurt_pot_aa = [*map(lambda p_aa: kurtosis(p_aa), potentials_aa)]\n",
    "    atrial_source = potentials_aa[kurt_pot_aa.index(max(kurt_pot_aa))]\n",
    "    return atrial_source\n",
    "    \n",
    "    \n",
    "def get_df_atrial():\n",
    "    files = os.listdir('tensor_data/6d2698_indexes')\n",
    "    rows = list()\n",
    "    for filename in files:\n",
    "        sources, contrib_sources = get_sources(filename)\n",
    "        # potentials_aa = get_likely_atrial(sources, contrib_sources)\n",
    "        #if potentials_aa.size != 0:\n",
    "        #    atrial_source = get_atrial_source(potentials_aa)\n",
    "        label = df.loc[int(filename.split('.')[0])].diagnostic\n",
    "        rows.append({\n",
    "              'id': int(filename.split('.')[0]),\n",
    "              'data': sources,\n",
    "              'label': label\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_atrial = get_df_atrial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_atrial = pd.read_pickle('df_atrial.pkl')\n",
    "label_encoder = LabelEncoder()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
