{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAAvDTEb3cBh",
    "outputId": "04885bf6-b991-443f-ff9b-6019c29d1f24",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:10:27.053903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-28 19:10:27.053919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/renan/√Årea de Trabalho/research-project/py37/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import timeit\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "import datetime \n",
    "import os\n",
    "\n",
    "from operator import itemgetter\n",
    "from scipy.signal import cheby2, resample, sosfilt\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat, savemat\n",
    "from tensorly import tensor as tensor_tly\n",
    "from tensorly import norm, dot\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l2, l1_l2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ecg_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database(object):\n",
    "  def __init__(self, path, leads):\n",
    "    self.path = path\n",
    "    self.leads = leads\n",
    "    self.freq = 0\n",
    "    self.headers_path = []\n",
    "    self.recordings_path = []\n",
    "    \n",
    "\n",
    "  def extract_from_drive(self):\n",
    "    if not os.path.exists(self.path):\n",
    "      with tarfile.open(self.path) as zip_file:\n",
    "        zip_file.extractall()\n",
    "    \n",
    "\n",
    "  def load_hea_file(self, i):\n",
    "    with open(self.headers_path[i], 'r') as f:\n",
    "      hea_file = f.read()\n",
    "    return hea_file\n",
    "\n",
    "\n",
    "  def get_frequency(self):\n",
    "    header = self.load_hea_file(0)\n",
    "    for i, l in enumerate(header.split('\\n')):\n",
    "        if i==0:\n",
    "            try:\n",
    "                self.freq = float(l.split(' ')[2])\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            break\n",
    "    print(f'Frequency: {self.freq}')\n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    return f'Database(folder={self.folder}, path_drive={self.path_drive}, freq={self.freq},  leads={self.leads}, headers_paths={len(self.headers_paths)}, recordings_paths={len(self.recordings_paths)})'\n",
    "\n",
    "\n",
    "  def load_paths(self):\n",
    "    for f in sorted(os.listdir(self.path)):\n",
    "      root, extension = os.path.splitext(f)\n",
    "      if not root.startswith('.') and extension=='.hea':\n",
    "        header_db_file = os.path.join(self.path, root + '.hea')\n",
    "        recording_db_file = os.path.join(self.path, root + '.mat')\n",
    "        if os.path.isfile(header_db_file) and os.path.isfile(recording_db_file):\n",
    "          self.headers_path.append(header_db_file)\n",
    "          self.recordings_path.append(recording_db_file)\n",
    "    print(f'Found {len(self.headers_path)} recordings in {self.path}.')\n",
    "    \n",
    "\n",
    "class Diagnostic(object):\n",
    "  diagnostics = []\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def append_diagnostic(cls, diagnostic):\n",
    "    cls.diagnostics.append(diagnostic)\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def get_diagnostics(cls):\n",
    "    return cls.diagnostics\n",
    "\n",
    "\n",
    "  def __init__(self, diag_name, abbrev, code):\n",
    "    self.name = diag_name\n",
    "    self.abbrev = abbrev\n",
    "    self.code = code\n",
    "    \n",
    "    \n",
    "\n",
    "class DiagnosticDatabase(object):\n",
    "  databases = []\n",
    "\n",
    "  @classmethod\n",
    "  def append_database(cls, diag_db):\n",
    "    cls.databases.append(diag_db)   \n",
    "\n",
    "    \n",
    "  @classmethod\n",
    "  def get_df_recordings(cls):  \n",
    "    total_recs = []\n",
    "    for diag_db in cls.databases:\n",
    "        recs = [rec.__dict__ for rec in diag_db.recordings_diag]\n",
    "        recs = [dict(rec, db=diag_db.db.path.split('/')[1], diagnostic=diag_db.diagnostic.abbrev) for rec in recs]\n",
    "        total_recs.append(recs)\n",
    "    total_recs = [rec for db in total_recs for rec in db]\n",
    "    dataframe = pd.DataFrame(total_recs)\n",
    "    return dataframe\n",
    "    \n",
    "\n",
    "  def __init__(self, diag_origin, db_origin):\n",
    "    self.diagnostic = diag_origin\n",
    "    self.db = db_origin\n",
    "    self.headers_diag_path = []\n",
    "    self.recordings_diag = []\n",
    "\n",
    "\n",
    "  def get_labels(self, header):\n",
    "    labels = list()\n",
    "    for l in header.split('\\n'):\n",
    "      if l.startswith('#Dx'):\n",
    "        try:\n",
    "          entries = l.split(': ')[1].split(',')\n",
    "          for entry in entries:\n",
    "            labels.append(entry.strip())\n",
    "        except:\n",
    "          pass\n",
    "    return labels\n",
    "\n",
    "\n",
    "  def get_leads(self,header):\n",
    "    leads = list()\n",
    "    for i, l in enumerate(header.split('\\n')):\n",
    "      entries = l.split(' ')\n",
    "      if i==0:\n",
    "        num_leads = int(entries[1])\n",
    "      elif i<=num_leads:\n",
    "        leads.append(entries[-1])\n",
    "      else:\n",
    "        break\n",
    "    return tuple(leads)\n",
    "\n",
    "\n",
    "  def choose_leads(self, recording, header, leads):\n",
    "    num_leads = len(leads)\n",
    "    num_samples = np.shape(recording)[1]\n",
    "    chosen_recording = np.zeros((num_leads, num_samples), recording.dtype)\n",
    "    available_leads = self.get_leads(header)\n",
    "    for i, lead in enumerate(leads):\n",
    "      if lead in available_leads:\n",
    "        j = available_leads.index(lead)\n",
    "        chosen_recording[i, :] = recording[j, :]\n",
    "    return chosen_recording\n",
    "\n",
    "\n",
    "  def plot_ecg(self, index):\n",
    "    ecg_plot.plot(self.rsp_cut_recordings_diag[index]/1000, sample_rate=self.db.freq/2, title='')\n",
    "    ecg_plot.show()\n",
    "\n",
    "    \n",
    "class Record():\n",
    "  def __init__(self, filename, inf, sup, data):\n",
    "    self.filename = filename\n",
    "    self.inf = inf\n",
    "    self.sup = sup\n",
    "    self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzVMxEyADvRx",
    "outputId": "34f8d11e-f247-4cba-e941-dd192d6d900d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10344 recordings in ../databases/WFDB_Ga.\n",
      "Frequency: 500.0\n",
      " - Found 570 recordings for AF.\n",
      " - Unattached 5690 intervals.\n",
      " - Found 1752 recordings for SR.\n",
      " - Unattached 17435 intervals.\n",
      "Found 74 recordings in ../databases/WFDB_StPetersburg.\n",
      "Frequency: 257.0\n",
      " - Found 2 recordings for AF.\n",
      " - Unattached 3600 intervals.\n",
      " - Found 0 recordings for SR.\n",
      " - Unattached 0 intervals.\n",
      "Found 516 recordings in ../databases/WFDB_PTB.\n",
      "Frequency: 1000.0\n",
      " - Found 15 recordings for AF.\n",
      " - Unattached 1341 intervals.\n",
      " - Found 80 recordings for SR.\n",
      " - Unattached 9435 intervals.\n",
      "Found 34905 recordings in ../databases/WFDB_Ningbo.\n",
      "Frequency: 500.0\n",
      " - Found 0 recordings for AF.\n",
      " - Unattached 0 intervals.\n"
     ]
    }
   ],
   "source": [
    "DiagnosticDatabase.databases = []\n",
    "Diagnostic.diagnostics = []\n",
    "\n",
    "af_diag = Diagnostic('Atrial Fibrilation', 'AF', '164889003')\n",
    "sr_diag = Diagnostic('Sinus Rhythm', 'SR', '426783006')\n",
    "Diagnostic.append_diagnostic(af_diag)\n",
    "Diagnostic.append_diagnostic(sr_diag)\n",
    "\n",
    "path_folder = '../databases/'\n",
    "available_databases = os.listdir(path_folder)\n",
    "#try:\n",
    "    #available_databases.remove('WFDB_PTB')\n",
    "    #available_databases.remove('WFDB_StPetersburg')\n",
    "#except ValueError:\n",
    "#    pass\n",
    "available_databases = list(map(lambda db: path_folder + db, available_databases))\n",
    "leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6')\n",
    "\n",
    "# Databases\n",
    "for path in available_databases:\n",
    "  folder = re.search('databases/(.*)', path).group(1)\n",
    "  db = Database(path, leads)\n",
    "  db.load_paths()\n",
    "  db.get_frequency()\n",
    "    \n",
    "  # Diagnostics\n",
    "  for diag in Diagnostic.get_diagnostics():\n",
    "    diag_db = DiagnosticDatabase(diag, db)\n",
    "    \n",
    "    # Recordings\n",
    "    for i, header_path in enumerate(diag_db.db.headers_path):\n",
    "      header = diag_db.db.load_hea_file(i)\n",
    "      labels = diag_db.get_labels(header)\n",
    "      if diag_db.diagnostic.code in labels:\n",
    "        # Get record\n",
    "        rec_file = header_path.replace('hea', 'mat')\n",
    "        recording = loadmat(rec_file)['val']\n",
    "        recording = diag_db.choose_leads(recording, header, diag_db.db.leads)\n",
    "        recording = np.array(recording, dtype=np.float64)\n",
    "        \n",
    "        # Filtering\n",
    "        sos = signal.cheby2(12, 20, [0.35, 70], \n",
    "                            'bandpass', \n",
    "                            fs= diag_db.db.freq, \n",
    "                            output='sos')\n",
    "        for lead in range(0, recording.shape[0]):\n",
    "            to_filt = np.array(recording[lead, :], dtype=np.float64)\n",
    "            filtered = signal.sosfilt(sos, to_filt)\n",
    "            recording[lead, :] = np.array(filtered, dtype=np.float64)\n",
    "\n",
    "        # Resample record to 250Hz\n",
    "        new_freq = 250\n",
    "        time_rec = len(recording[0])/diag_db.db.freq\n",
    "        n_samples = int(time_rec*new_freq)\n",
    "        recording = resample(recording, n_samples, axis=1)\n",
    "\n",
    "        # Cut record in 250 samples\n",
    "        interval = 250\n",
    "        size_rec = recording.shape[1]\n",
    "        samples_rec = math.floor(size_rec/interval)\n",
    "        for i in range(0, samples_rec):\n",
    "          inf = i*interval\n",
    "          sup = ((i+1)*interval)\n",
    "          recording_interval = np.array(list(map(lambda lead: lead[inf:sup], recording)))\n",
    "          rec_filename = rec_file.split('/')[-1]\n",
    "          record = Record(rec_filename, \n",
    "                          inf, \n",
    "                          sup, \n",
    "                          recording_interval)\n",
    "          diag_db.recordings_diag.append(record)\n",
    "        diag_db.headers_diag_path.append(header_path)\n",
    "    print(f' - Found {len(diag_db.headers_diag_path)} recordings for {diag_db.diagnostic.abbrev}.')\n",
    "    print(f' - Unattached {len(diag_db.recordings_diag)} intervals.')\n",
    "    DiagnosticDatabase.append_database(diag_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 343213 rows\n",
      "AF: 54191 rows\n",
      "SR: 289022 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diagnostic  db                  \n",
       "AF          WFDB_CPSC2018            18306\n",
       "            WFDB_CPSC2018_2           2325\n",
       "            WFDB_ChapmanShaoxing     12730\n",
       "            WFDB_Ga                   5690\n",
       "            WFDB_PTBXL               15140\n",
       "SR          WFDB_CPSC2018            14116\n",
       "            WFDB_CPSC2018_2             61\n",
       "            WFDB_ChapmanShaoxing     13500\n",
       "            WFDB_Ga                  17435\n",
       "            WFDB_Ningbo              62990\n",
       "            WFDB_PTBXL              180920\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DiagnosticDatabase.get_df_recordings()\n",
    "%reset_selective -f \"^DiagnosticDatabase$\"\n",
    "df = df.sample(frac=1)\n",
    "print(f\"TOTAL: {df.shape[0]} rows\")\n",
    "print(f\"AF: {str(df[df.diagnostic == 'AF'].shape[0])} rows\")\n",
    "print(f\"SR: {str(df[df.diagnostic == 'SR'].shape[0])} rows\")\n",
    "df.groupby(['diagnostic', 'db']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get balanced class database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>inf</th>\n",
       "      <th>sup</th>\n",
       "      <th>data</th>\n",
       "      <th>db</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44411</th>\n",
       "      <td>JS09378.mat</td>\n",
       "      <td>2250</td>\n",
       "      <td>2500</td>\n",
       "      <td>[[-128.0879443366401, -104.21847447001475, -88...</td>\n",
       "      <td>WFDB_ChapmanShaoxing</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70423</th>\n",
       "      <td>HR17763.mat</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>[[-107.89988426190651, -103.50782912232864, -9...</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>A3330.mat</td>\n",
       "      <td>500</td>\n",
       "      <td>750</td>\n",
       "      <td>[[80.2774680970738, 96.89598938208577, 130.342...</td>\n",
       "      <td>WFDB_CPSC2018</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40505</th>\n",
       "      <td>JS06384.mat</td>\n",
       "      <td>750</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[15.932645392231233, 9.929720055698139, 7.753...</td>\n",
       "      <td>WFDB_ChapmanShaoxing</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>HR17218.mat</td>\n",
       "      <td>2000</td>\n",
       "      <td>2250</td>\n",
       "      <td>[[-14.919627355289675, -11.344026050587406, -1...</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131090</th>\n",
       "      <td>HR06708.mat</td>\n",
       "      <td>2000</td>\n",
       "      <td>2250</td>\n",
       "      <td>[[0.11071115119102179, 16.821644843473088, 26....</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107662</th>\n",
       "      <td>HR03921.mat</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>[[-8.788790370574128, -88.98056763364761, -162...</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146251</th>\n",
       "      <td>HR08548.mat</td>\n",
       "      <td>2250</td>\n",
       "      <td>2500</td>\n",
       "      <td>[[-44.052050494166345, -45.13386392416353, -43...</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327193</th>\n",
       "      <td>JS39879.mat</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>[[-78.57974147865943, -6.454119299492508, -55....</td>\n",
       "      <td>WFDB_Ningbo</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76471</th>\n",
       "      <td>HR00292.mat</td>\n",
       "      <td>2250</td>\n",
       "      <td>2500</td>\n",
       "      <td>[[-26.363753809658586, -27.618977576512858, -2...</td>\n",
       "      <td>WFDB_PTBXL</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108382 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename   inf   sup  \\\n",
       "44411   JS09378.mat  2250  2500   \n",
       "70423   HR17763.mat   250   500   \n",
       "9018      A3330.mat   500   750   \n",
       "40505   JS06384.mat   750  1000   \n",
       "70000   HR17218.mat  2000  2250   \n",
       "...             ...   ...   ...   \n",
       "131090  HR06708.mat  2000  2250   \n",
       "107662  HR03921.mat     0   250   \n",
       "146251  HR08548.mat  2250  2500   \n",
       "327193  JS39879.mat     0   250   \n",
       "76471   HR00292.mat  2250  2500   \n",
       "\n",
       "                                                     data  \\\n",
       "44411   [[-128.0879443366401, -104.21847447001475, -88...   \n",
       "70423   [[-107.89988426190651, -103.50782912232864, -9...   \n",
       "9018    [[80.2774680970738, 96.89598938208577, 130.342...   \n",
       "40505   [[15.932645392231233, 9.929720055698139, 7.753...   \n",
       "70000   [[-14.919627355289675, -11.344026050587406, -1...   \n",
       "...                                                   ...   \n",
       "131090  [[0.11071115119102179, 16.821644843473088, 26....   \n",
       "107662  [[-8.788790370574128, -88.98056763364761, -162...   \n",
       "146251  [[-44.052050494166345, -45.13386392416353, -43...   \n",
       "327193  [[-78.57974147865943, -6.454119299492508, -55....   \n",
       "76471   [[-26.363753809658586, -27.618977576512858, -2...   \n",
       "\n",
       "                          db diagnostic  \n",
       "44411   WFDB_ChapmanShaoxing         AF  \n",
       "70423             WFDB_PTBXL         AF  \n",
       "9018           WFDB_CPSC2018         AF  \n",
       "40505   WFDB_ChapmanShaoxing         AF  \n",
       "70000             WFDB_PTBXL         AF  \n",
       "...                      ...        ...  \n",
       "131090            WFDB_PTBXL         SR  \n",
       "107662            WFDB_PTBXL         SR  \n",
       "146251            WFDB_PTBXL         SR  \n",
       "327193           WFDB_Ningbo         SR  \n",
       "76471             WFDB_PTBXL         SR  \n",
       "\n",
       "[108382 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b = df.groupby('diagnostic')\n",
    "df_b = df_b.apply(lambda x: x.sample(df_b.size().min()))\n",
    "df_b = df_b.droplevel(level=0)\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(datetime.datetime.now())\n",
    "filename = filename.replace(' ', '_').replace(':', '_').replace('.', '_')\n",
    "filename = '_'.join(filename.split('_')[:-1])\n",
    "df_b.to_pickle(f'{filename}.pkl')  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
