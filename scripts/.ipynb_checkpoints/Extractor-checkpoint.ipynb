{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAAvDTEb3cBh",
    "outputId": "04885bf6-b991-443f-ff9b-6019c29d1f24",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:10:27.053903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-28 19:10:27.053919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/renan/Área de Trabalho/research-project/py37/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import timeit\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "import datetime \n",
    "import os\n",
    "\n",
    "from operator import itemgetter\n",
    "from scipy.signal import cheby2, resample, sosfilt\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat, savemat\n",
    "from tensorly import tensor as tensor_tly\n",
    "from tensorly import norm, dot\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l2, l1_l2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ecg_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database(object):\n",
    "  def __init__(self, path, leads):\n",
    "    self.path = path\n",
    "    self.leads = leads\n",
    "    self.freq = 0\n",
    "    self.headers_path = []\n",
    "    self.recordings_path = []\n",
    "    \n",
    "\n",
    "  def extract_from_drive(self):\n",
    "    if not os.path.exists(self.path):\n",
    "      with tarfile.open(self.path) as zip_file:\n",
    "        zip_file.extractall()\n",
    "    \n",
    "\n",
    "  def load_hea_file(self, i):\n",
    "    with open(self.headers_path[i], 'r') as f:\n",
    "      hea_file = f.read()\n",
    "    return hea_file\n",
    "\n",
    "\n",
    "  def get_frequency(self):\n",
    "    header = self.load_hea_file(0)\n",
    "    for i, l in enumerate(header.split('\\n')):\n",
    "        if i==0:\n",
    "            try:\n",
    "                self.freq = float(l.split(' ')[2])\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            break\n",
    "    print(f'Frequency: {self.freq}')\n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    return f'Database(folder={self.folder}, path_drive={self.path_drive}, freq={self.freq},  leads={self.leads}, headers_paths={len(self.headers_paths)}, recordings_paths={len(self.recordings_paths)})'\n",
    "\n",
    "\n",
    "  def load_paths(self):\n",
    "    for f in sorted(os.listdir(self.path)):\n",
    "      root, extension = os.path.splitext(f)\n",
    "      if not root.startswith('.') and extension=='.hea':\n",
    "        header_db_file = os.path.join(self.path, root + '.hea')\n",
    "        recording_db_file = os.path.join(self.path, root + '.mat')\n",
    "        if os.path.isfile(header_db_file) and os.path.isfile(recording_db_file):\n",
    "          self.headers_path.append(header_db_file)\n",
    "          self.recordings_path.append(recording_db_file)\n",
    "    print(f'Found {len(self.headers_path)} recordings in {self.path}.')\n",
    "    \n",
    "\n",
    "class Diagnostic(object):\n",
    "  diagnostics = []\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def append_diagnostic(cls, diagnostic):\n",
    "    cls.diagnostics.append(diagnostic)\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def get_diagnostics(cls):\n",
    "    return cls.diagnostics\n",
    "\n",
    "\n",
    "  def __init__(self, diag_name, abbrev, code):\n",
    "    self.name = diag_name\n",
    "    self.abbrev = abbrev\n",
    "    self.code = code\n",
    "    \n",
    "    \n",
    "\n",
    "class DiagnosticDatabase(object):\n",
    "  databases = []\n",
    "\n",
    "  @classmethod\n",
    "  def append_database(cls, diag_db):\n",
    "    cls.databases.append(diag_db)   \n",
    "\n",
    "    \n",
    "  @classmethod\n",
    "  def get_df_recordings(cls):  \n",
    "    total_recs = []\n",
    "    for diag_db in cls.databases:\n",
    "        recs = [rec.__dict__ for rec in diag_db.recordings_diag]\n",
    "        recs = [dict(rec, db=diag_db.db.path.split('/')[1], diagnostic=diag_db.diagnostic.abbrev) for rec in recs]\n",
    "        total_recs.append(recs)\n",
    "    total_recs = [rec for db in total_recs for rec in db]\n",
    "    dataframe = pd.DataFrame(total_recs)\n",
    "    return dataframe\n",
    "    \n",
    "\n",
    "  def __init__(self, diag_origin, db_origin):\n",
    "    self.diagnostic = diag_origin\n",
    "    self.db = db_origin\n",
    "    self.headers_diag_path = []\n",
    "    self.recordings_diag = []\n",
    "\n",
    "\n",
    "  def get_labels(self, header):\n",
    "    labels = list()\n",
    "    for l in header.split('\\n'):\n",
    "      if l.startswith('#Dx'):\n",
    "        try:\n",
    "          entries = l.split(': ')[1].split(',')\n",
    "          for entry in entries:\n",
    "            labels.append(entry.strip())\n",
    "        except:\n",
    "          pass\n",
    "    return labels\n",
    "\n",
    "\n",
    "  def get_leads(self,header):\n",
    "    leads = list()\n",
    "    for i, l in enumerate(header.split('\\n')):\n",
    "      entries = l.split(' ')\n",
    "      if i==0:\n",
    "        num_leads = int(entries[1])\n",
    "      elif i<=num_leads:\n",
    "        leads.append(entries[-1])\n",
    "      else:\n",
    "        break\n",
    "    return tuple(leads)\n",
    "\n",
    "\n",
    "  def choose_leads(self, recording, header, leads):\n",
    "    num_leads = len(leads)\n",
    "    num_samples = np.shape(recording)[1]\n",
    "    chosen_recording = np.zeros((num_leads, num_samples), recording.dtype)\n",
    "    available_leads = self.get_leads(header)\n",
    "    for i, lead in enumerate(leads):\n",
    "      if lead in available_leads:\n",
    "        j = available_leads.index(lead)\n",
    "        chosen_recording[i, :] = recording[j, :]\n",
    "    return chosen_recording\n",
    "\n",
    "\n",
    "  def plot_ecg(self, index):\n",
    "    ecg_plot.plot(self.rsp_cut_recordings_diag[index]/1000, sample_rate=self.db.freq/2, title='')\n",
    "    ecg_plot.show()\n",
    "\n",
    "    \n",
    "class Record():\n",
    "  def __init__(self, filename, inf, sup, data):\n",
    "    self.filename = filename\n",
    "    self.inf = inf\n",
    "    self.sup = sup\n",
    "    self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzVMxEyADvRx",
    "outputId": "34f8d11e-f247-4cba-e941-dd192d6d900d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10344 recordings in ../databases/WFDB_Ga.\n",
      "Frequency: 500.0\n",
      " - Found 570 recordings for AF.\n",
      " - Unattached 5690 intervals.\n",
      " - Found 1752 recordings for SR.\n",
      " - Unattached 17435 intervals.\n",
      "Found 74 recordings in ../databases/WFDB_StPetersburg.\n",
      "Frequency: 257.0\n",
      " - Found 2 recordings for AF.\n",
      " - Unattached 3600 intervals.\n",
      " - Found 0 recordings for SR.\n",
      " - Unattached 0 intervals.\n",
      "Found 516 recordings in ../databases/WFDB_PTB.\n",
      "Frequency: 1000.0\n",
      " - Found 15 recordings for AF.\n",
      " - Unattached 1341 intervals.\n",
      " - Found 80 recordings for SR.\n",
      " - Unattached 9435 intervals.\n",
      "Found 34905 recordings in ../databases/WFDB_Ningbo.\n",
      "Frequency: 500.0\n",
      " - Found 0 recordings for AF.\n",
      " - Unattached 0 intervals.\n",
      " - Found 6299 recordings for SR.\n",
      " - Unattached 62990 intervals.\n",
      "Found 3453 recordings in ../databases/WFDB_CPSC2018_2.\n",
      "Frequency: 500.0\n",
      " - Found 153 recordings for AF.\n",
      " - Unattached 2325 intervals.\n",
      " - Found 4 recordings for SR.\n",
      " - Unattached 61 intervals.\n",
      "Found 6877 recordings in ../databases/WFDB_CPSC2018.\n",
      "Frequency: 500.0\n",
      " - Found 1221 recordings for AF.\n",
      " - Unattached 18306 intervals.\n",
      " - Found 918 recordings for SR.\n",
      " - Unattached 14116 intervals.\n",
      "Found 21837 recordings in ../databases/WFDB_PTBXL.\n",
      "Frequency: 500.0\n",
      " - Found 1514 recordings for AF.\n",
      " - Unattached 15140 intervals.\n",
      " - Found 18092 recordings for SR.\n",
      " - Unattached 180920 intervals.\n",
      "Found 7497 recordings in ../databases/WFDB_ChapmanShaoxing.\n",
      "Frequency: 500.0\n",
      " - Found 1273 recordings for AF.\n",
      " - Unattached 12730 intervals.\n",
      " - Found 1350 recordings for SR.\n",
      " - Unattached 13500 intervals.\n"
     ]
    }
   ],
   "source": [
    "DiagnosticDatabase.databases = []\n",
    "Diagnostic.diagnostics = []\n",
    "\n",
    "af_diag = Diagnostic('Atrial Fibrilation', 'AF', '164889003')\n",
    "sr_diag = Diagnostic('Sinus Rhythm', 'SR', '426783006')\n",
    "Diagnostic.append_diagnostic(af_diag)\n",
    "Diagnostic.append_diagnostic(sr_diag)\n",
    "\n",
    "path_folder = '../databases/'\n",
    "available_databases = os.listdir(path_folder)\n",
    "#try:\n",
    "    #available_databases.remove('WFDB_PTB')\n",
    "    #available_databases.remove('WFDB_StPetersburg')\n",
    "#except ValueError:\n",
    "#    pass\n",
    "available_databases = list(map(lambda db: path_folder + db, available_databases))\n",
    "leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6')\n",
    "\n",
    "# Databases\n",
    "for path in available_databases:\n",
    "  folder = re.search('databases/(.*)', path).group(1)\n",
    "  db = Database(path, leads)\n",
    "  db.load_paths()\n",
    "  db.get_frequency()\n",
    "    \n",
    "  # Diagnostics\n",
    "  for diag in Diagnostic.get_diagnostics():\n",
    "    diag_db = DiagnosticDatabase(diag, db)\n",
    "    \n",
    "    # Recordings\n",
    "    for i, header_path in enumerate(diag_db.db.headers_path):\n",
    "      header = diag_db.db.load_hea_file(i)\n",
    "      labels = diag_db.get_labels(header)\n",
    "      if diag_db.diagnostic.code in labels:\n",
    "        # Get record\n",
    "        rec_file = header_path.replace('hea', 'mat')\n",
    "        recording = loadmat(rec_file)['val']\n",
    "        recording = diag_db.choose_leads(recording, header, diag_db.db.leads)\n",
    "        recording = np.array(recording, dtype=np.float64)\n",
    "        \n",
    "        # Filtering\n",
    "        sos = signal.cheby2(12, 20, [0.35, 70], \n",
    "                            'bandpass', \n",
    "                            fs= diag_db.db.freq, \n",
    "                            output='sos')\n",
    "        for lead in range(0, recording.shape[0]):\n",
    "            to_filt = np.array(recording[lead, :], dtype=np.float64)\n",
    "            filtered = signal.sosfilt(sos, to_filt)\n",
    "            recording[lead, :] = np.array(filtered, dtype=np.float64)\n",
    "\n",
    "        # Resample record to 250Hz\n",
    "        new_freq = 250\n",
    "        time_rec = len(recording[0])/diag_db.db.freq\n",
    "        n_samples = int(time_rec*new_freq)\n",
    "        recording = resample(recording, n_samples, axis=1)\n",
    "\n",
    "        # Cut record in 250 samples\n",
    "        interval = 250\n",
    "        size_rec = recording.shape[1]\n",
    "        samples_rec = math.floor(size_rec/interval)\n",
    "        for i in range(0, samples_rec):\n",
    "          inf = i*interval\n",
    "          sup = ((i+1)*interval)\n",
    "          recording_interval = np.array(list(map(lambda lead: lead[inf:sup], recording)))\n",
    "          rec_filename = rec_file.split('/')[-1]\n",
    "          record = Record(rec_filename, \n",
    "                          inf, \n",
    "                          sup, \n",
    "                          recording_interval)\n",
    "          diag_db.recordings_diag.append(record)\n",
    "        diag_db.headers_diag_path.append(header_path)\n",
    "    print(f' - Found {len(diag_db.headers_diag_path)} recordings for {diag_db.diagnostic.abbrev}.')\n",
    "    print(f' - Unattached {len(diag_db.recordings_diag)} intervals.')\n",
    "    DiagnosticDatabase.append_database(diag_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 357589 rows\n",
      "AF: 59132 rows\n",
      "SR: 298457 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diagnostic  db       \n",
       "AF          databases     59132\n",
       "SR          databases    298457\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DiagnosticDatabase.get_df_recordings()\n",
    "%reset_selective -f \"^DiagnosticDatabase$\"\n",
    "df = df.sample(frac=1)\n",
    "print(f\"TOTAL: {df.shape[0]} rows\")\n",
    "print(f\"AF: {str(df[df.diagnostic == 'AF'].shape[0])} rows\")\n",
    "print(f\"SR: {str(df[df.diagnostic == 'SR'].shape[0])} rows\")\n",
    "df.groupby(['diagnostic', 'db']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get balanced class database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>inf</th>\n",
       "      <th>sup</th>\n",
       "      <th>data</th>\n",
       "      <th>db</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334276</th>\n",
       "      <td>JS02349.mat</td>\n",
       "      <td>1750</td>\n",
       "      <td>2000</td>\n",
       "      <td>[[-7.196979998059459, -17.227663931933506, -30...</td>\n",
       "      <td>databases</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113817</th>\n",
       "      <td>A4158.mat</td>\n",
       "      <td>1250</td>\n",
       "      <td>1500</td>\n",
       "      <td>[[-72.71772528082523, -69.42428411249715, -69....</td>\n",
       "      <td>databases</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23730</th>\n",
       "      <td>I0049.mat</td>\n",
       "      <td>151250</td>\n",
       "      <td>151500</td>\n",
       "      <td>[[-177.97506264040737, -176.25399870561907, -1...</td>\n",
       "      <td>databases</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053</th>\n",
       "      <td>I0049.mat</td>\n",
       "      <td>232000</td>\n",
       "      <td>232250</td>\n",
       "      <td>[[20.167173296569008, 22.462589312722237, 22.9...</td>\n",
       "      <td>databases</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24574</th>\n",
       "      <td>I0049.mat</td>\n",
       "      <td>362250</td>\n",
       "      <td>362500</td>\n",
       "      <td>[[-88.54836200954301, -84.21898884299921, -81....</td>\n",
       "      <td>databases</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308698</th>\n",
       "      <td>HR18939.mat</td>\n",
       "      <td>2250</td>\n",
       "      <td>2500</td>\n",
       "      <td>[[-40.16797066449827, -42.409213808409845, -44...</td>\n",
       "      <td>databases</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306371</th>\n",
       "      <td>HR18654.mat</td>\n",
       "      <td>500</td>\n",
       "      <td>750</td>\n",
       "      <td>[[-51.48686351908005, -70.19114117157837, -84....</td>\n",
       "      <td>databases</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158424</th>\n",
       "      <td>HR00915.mat</td>\n",
       "      <td>1250</td>\n",
       "      <td>1500</td>\n",
       "      <td>[[-36.7280623625614, -26.21199411477894, -24.8...</td>\n",
       "      <td>databases</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254229</th>\n",
       "      <td>HR12315.mat</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>[[12.960585205688535, -41.18561151880605, -64....</td>\n",
       "      <td>databases</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322422</th>\n",
       "      <td>HR20676.mat</td>\n",
       "      <td>750</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[-39.23074893054348, -37.57909787667053, -43....</td>\n",
       "      <td>databases</td>\n",
       "      <td>SR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118264 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename     inf     sup  \\\n",
       "334276  JS02349.mat    1750    2000   \n",
       "113817    A4158.mat    1250    1500   \n",
       "23730     I0049.mat  151250  151500   \n",
       "24053     I0049.mat  232000  232250   \n",
       "24574     I0049.mat  362250  362500   \n",
       "...             ...     ...     ...   \n",
       "308698  HR18939.mat    2250    2500   \n",
       "306371  HR18654.mat     500     750   \n",
       "158424  HR00915.mat    1250    1500   \n",
       "254229  HR12315.mat       0     250   \n",
       "322422  HR20676.mat     750    1000   \n",
       "\n",
       "                                                     data         db  \\\n",
       "334276  [[-7.196979998059459, -17.227663931933506, -30...  databases   \n",
       "113817  [[-72.71772528082523, -69.42428411249715, -69....  databases   \n",
       "23730   [[-177.97506264040737, -176.25399870561907, -1...  databases   \n",
       "24053   [[20.167173296569008, 22.462589312722237, 22.9...  databases   \n",
       "24574   [[-88.54836200954301, -84.21898884299921, -81....  databases   \n",
       "...                                                   ...        ...   \n",
       "308698  [[-40.16797066449827, -42.409213808409845, -44...  databases   \n",
       "306371  [[-51.48686351908005, -70.19114117157837, -84....  databases   \n",
       "158424  [[-36.7280623625614, -26.21199411477894, -24.8...  databases   \n",
       "254229  [[12.960585205688535, -41.18561151880605, -64....  databases   \n",
       "322422  [[-39.23074893054348, -37.57909787667053, -43....  databases   \n",
       "\n",
       "       diagnostic  \n",
       "334276         AF  \n",
       "113817         AF  \n",
       "23730          AF  \n",
       "24053          AF  \n",
       "24574          AF  \n",
       "...           ...  \n",
       "308698         SR  \n",
       "306371         SR  \n",
       "158424         SR  \n",
       "254229         SR  \n",
       "322422         SR  \n",
       "\n",
       "[118264 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_b = df.groupby('diagnostic')\n",
    "# df_b = df_b.apply(lambda x: x.sample(df_b.size().min()))\n",
    "# df_b = df_b.droplevel(level=0)\n",
    "# df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(datetime.datetime.now())\n",
    "filename = filename.replace(' ', '_').replace(':', '_').replace('.', '_')\n",
    "filename = '_'.join(filename.split('_')[:-1])\n",
    "df_b.to_pickle(f'{filename}.pkl')  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
