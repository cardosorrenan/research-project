{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8381ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e481ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mbarzegary/ecg-classification-keras-cnn/blob/master/train_keras.py\n",
    "def cnn_2(input_shape):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(64, (4, 4), input_shape=input_shape, padding='same', kernel_regularizer=l1_l2(0.0001, 0.0001), activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, (4, 4), kernel_regularizer=l2(0.0001), padding='same', activation='relu'))\n",
    "  model.add(MaxPooling2D((4, 4)))\n",
    "  model.add(Dropout(0.20))\n",
    "  model.add(Conv2D(256, (4, 4), kernel_regularizer=l2(0.0001), padding='same', activation='relu'))\n",
    "  model.add(Conv2D(256, (4, 4), kernel_regularizer=l2(0.0001), padding='same', activation='relu'))\n",
    "  model.add(MaxPooling2D())\n",
    "  model.add(Dropout(0.20))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, kernel_regularizer=l2(0.0001), activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(2, activation='softmax'))\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "\n",
    "def build_model(model, epochs, batch_size, train_x, test_x, train_y, test_y):\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  callbacks_list = [\n",
    "      keras.callbacks.ModelCheckpoint(\n",
    "          filepath='model.h5',\n",
    "          monitor='val_loss', save_best_only=True, verbose=1),\n",
    "      keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "  ]\n",
    "\n",
    "  return model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   callbacks = callbacks_list,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "def plot_results(model):  \n",
    "  fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "  ax[0].plot(model.history['loss'], color='b', label=\"Training loss\")\n",
    "  ax[0].plot(model.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "  legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "  ax[1].plot(model.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "  ax[1].plot(model.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "  legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ea94f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recordings_AF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_179295/2269763284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecordings_AF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecordings_SR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecordings_AF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecordings_SR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recordings_AF' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.vstack((recordings_AF, recordings_SR))\n",
    "y = np.hstack((np.ones(len(recordings_AF)).T, np.zeros(len(recordings_SR)).T))\n",
    "y = keras.utils.to_categorical(y, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train = X_train.reshape([*X_train.shape[0:3], 1])\n",
    "X_test = X_test.reshape([*X_test.shape[0:3], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn_2(X_train.shape[1:])\n",
    "# net = cnn_2()\n",
    "batch_size = 124\n",
    "epochs = 10\n",
    "model = build_model(net, epochs, batch_size, X_train, y_train, X_test, y_test)\n",
    "plot_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('/content/gdrive/MyDrive/Pesquisa Mestrado/Parte II (Novembro-)/Databases/Models/Model1.h5')\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
